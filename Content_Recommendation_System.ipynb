{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritaban26/Content-Recommendation-System/blob/main/Content_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Definition & Objective**\n",
        "\n",
        "##üé®Colour-Based Image Recommendation System.\n",
        "\n",
        "##Problem Statement:-\n",
        "In this rapidly expanding sea of digital design and visual art, professionals are confronted with an unprecedented volume of visual content across platforms such as Pinterest, Google Images, and Shutterstock. While these repositories offer vast resources, they create a significant challenge regarding information overload. Designers and artists frequently struggle to streamline their inspiration workflows, as locating specific imagery that aligns with a precise visual theme is time-consuming and inefficient.\n",
        "\n",
        "\n",
        "##Real-world Relevance and Motivation:-\n",
        "The motivation for this project stems from a practical workflow inefficiency encountered in my photography and web design. When I attempted to source images from an existing library to match a specific website theme (e.g., a green color palette), traditional search methods proved inadequate. This highlighted a distinct need for a system capable of filtering and recommending content based on specific color metrics.\n"
      ],
      "metadata": {
        "id": "ftZEzMmwZrC6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## 1Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install all required packages\n",
        "!pip install numpy>=1.24.0 \\\n",
        "             scikit-image>=0.21.0 \\\n",
        "             Pillow>=10.0.0 \\\n",
        "             faiss-cpu>=1.7.4 \\\n",
        "             scikit-learn>=1.3.0 \\\n",
        "             colorthief>=0.2.1 \\\n",
        "             ipywidgets>=8.0.0 \\\n",
        "             matplotlib>=3.7.0\n",
        "\n",
        "print(\"‚úì Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# Configure matplotlib\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "print(\"‚úì Standard imports complete!\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"NumPy: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## 2Ô∏è‚É£ Data Understanding & Preparation\n",
        "\n",
        "**Dataset Source:** Using my own local catelog of images. Upload a folder containing your images (supports: .jpg, .png, .bmp, .gif, .webp)\n",
        "\n",
        "\n",
        "### Option A: Upload ZIP of images (Recommended)\n",
        "Create a ZIP of your images folder and upload it below.\n",
        "\n",
        "### Option B: Mount Google Drive\n",
        "If your images are in Google Drive, use the alternate cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_images"
      },
      "outputs": [],
      "source": [
        "# Upload ZIP of images\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"üì§ Upload a ZIP file containing your images...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract ZIP\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"\\nüì¶ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('images')\n",
        "        print(\"‚úì Extraction complete!\")\n",
        "        break\n",
        "\n",
        "# Set image directory\n",
        "IMAGE_DIR = 'images'\n",
        "\n",
        "# List uploaded images\n",
        "!ls -lh images/\n",
        "print(f\"\\n‚úì Images ready in: {IMAGE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive_alt"
      },
      "outputs": [],
      "source": [
        "# ALTERNATIVE: Mount Google Drive (UNCOMMENT TO USE)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "#\n",
        "# # Set path to your images folder in Drive\n",
        "# IMAGE_DIR = '/content/drive/MyDrive/your_images_folder'\n",
        "# print(f\"‚úì Using images from: {IMAGE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading & Exploration:**\n",
        "\n",
        "-Validates image files for various file formats.\n",
        "\n",
        "-Images are resized equally to ensure consistency during analysis.\n",
        "\n",
        "-Loads the metadata for the images(file paths, image size)."
      ],
      "metadata": {
        "id": "E3-LP-NzHU-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_ingestion"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Data Ingestion Module\n",
        "# ============================================================================\n",
        "\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ImageDataset:\n",
        "    \"\"\"Manages image collection from directory.\"\"\"\n",
        "\n",
        "    def __init__(self, image_dir: str):\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.images: List[Dict] = []\n",
        "        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}\n",
        "\n",
        "        if not self.image_dir.exists():\n",
        "            raise ValueError(f\"Directory does not exist: {image_dir}\")\n",
        "\n",
        "    def load_images(self, recursive: bool = True, max_size: Optional[tuple] = None) -> List[Dict]:\n",
        "        \"\"\"Load all images from directory.\"\"\"\n",
        "        logger.info(f\"Loading images from {self.image_dir}\")\n",
        "\n",
        "        if recursive:\n",
        "            image_paths = []\n",
        "            for ext in self.supported_formats:\n",
        "                image_paths.extend(self.image_dir.rglob(f\"*{ext}\"))\n",
        "                image_paths.extend(self.image_dir.rglob(f\"*{ext.upper()}\"))\n",
        "        else:\n",
        "            image_paths = []\n",
        "            for ext in self.supported_formats:\n",
        "                image_paths.extend(self.image_dir.glob(f\"*{ext}\"))\n",
        "                image_paths.extend(self.image_dir.glob(f\"*{ext.upper()}\"))\n",
        "\n",
        "        image_paths = sorted(set(image_paths))\n",
        "        logger.info(f\"Found {len(image_paths)} image files\")\n",
        "\n",
        "        for img_path in image_paths:\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                if max_size:\n",
        "                    img.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "                self.images.append({\n",
        "                    'path': str(img_path),\n",
        "                    'filename': img_path.name,\n",
        "                    'size': img.size,\n",
        "                    'format': img.format,\n",
        "                    'image': img\n",
        "                })\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed to load {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        logger.info(f\"Successfully loaded {len(self.images)} images\")\n",
        "        return self.images\n",
        "\n",
        "    def get_statistics(self) -> Dict:\n",
        "        \"\"\"Get dataset statistics.\"\"\"\n",
        "        if not self.images:\n",
        "            return {}\n",
        "\n",
        "        return {\n",
        "            'total_images': len(self.images),\n",
        "            'directory': str(self.image_dir)\n",
        "        }\n",
        "\n",
        "def load_images_from_directory(directory: str, recursive: bool = True,\n",
        "                               max_size: Optional[tuple] = (800, 800)) -> ImageDataset:\n",
        "    \"\"\"Load images from directory.\"\"\"\n",
        "    dataset = ImageDataset(directory)\n",
        "    dataset.load_images(recursive=recursive, max_size=max_size)\n",
        "    return dataset\n",
        "\n",
        "print(\"‚úì ImageDataset loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing & Feature Extraction:**\n",
        "\n",
        "-The top 5 dominat colours are extracted from the images using k-means clustering.\n",
        "\n",
        "-Coverting from RGB colour space to LAB colour space, so as to ensure similarity as to how humans percive colour."
      ],
      "metadata": {
        "id": "MgLjAd9SGgff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_extraction"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Feature Extraction Module\n",
        "# ============================================================================\n",
        "\n",
        "from colorthief import ColorThief\n",
        "from skimage import color as skcolor\n",
        "from sklearn.cluster import KMeans\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import io\n",
        "\n",
        "class ColorFeatureExtractor:\n",
        "    \"\"\"Extracts color features from images for similarity search.\"\"\"\n",
        "\n",
        "    def __init__(self, n_colors: int = 5, quality: int = 10):\n",
        "        self.n_colors = n_colors\n",
        "        self.quality = quality\n",
        "\n",
        "    def extract_dominant_colors(self, image: Image.Image) -> List[Tuple[int, int, int]]:\n",
        "        \"\"\"Extract dominant colors using k-means clustering.\"\"\"\n",
        "        try:\n",
        "            img_array = np.array(image)\n",
        "            pixels = img_array.reshape(-1, 3)\n",
        "\n",
        "            if len(pixels) > 10000:\n",
        "                indices = np.random.choice(len(pixels), 10000, replace=False)\n",
        "                pixels = pixels[indices]\n",
        "\n",
        "            kmeans = KMeans(\n",
        "                n_clusters=self.n_colors,\n",
        "                random_state=42,\n",
        "                n_init=10,\n",
        "                max_iter=500,\n",
        "                tol=1e-6\n",
        "            )\n",
        "            kmeans.fit(pixels)\n",
        "\n",
        "            colors = kmeans.cluster_centers_.astype(int)\n",
        "            labels = kmeans.labels_\n",
        "            unique, counts = np.unique(labels, return_counts=True)\n",
        "            sorted_indices = np.argsort(-counts)\n",
        "            colors = colors[sorted_indices]\n",
        "\n",
        "            return [tuple(color) for color in colors]\n",
        "        except Exception as e:\n",
        "            return [(128, 128, 128)] * self.n_colors\n",
        "\n",
        "    def rgb_to_lab(self, rgb: Tuple[int, int, int]) -> Tuple[float, float, float]:\n",
        "        \"\"\"Convert RGB to LAB color space.\"\"\"\n",
        "        rgb_normalized = np.array([[rgb]]) / 255.0\n",
        "        lab = skcolor.rgb2lab(rgb_normalized)\n",
        "        return tuple(lab[0, 0])\n",
        "\n",
        "    def create_feature_vector(self, image: Image.Image) -> np.ndarray:\n",
        "        \"\"\"Create feature vector from image.\"\"\"\n",
        "        rgb_colors = self.extract_dominant_colors(image)\n",
        "        lab_colors = [self.rgb_to_lab(rgb) for rgb in rgb_colors]\n",
        "        feature_vector = np.array(lab_colors).flatten()\n",
        "        return feature_vector.astype(np.float32)\n",
        "\n",
        "    def extract_color_palette(self, image: Image.Image) -> Dict:\n",
        "        \"\"\"Extract color palette with RGB and LAB representations.\"\"\"\n",
        "        rgb_colors = self.extract_dominant_colors(image)\n",
        "        lab_colors = [self.rgb_to_lab(rgb) for rgb in rgb_colors]\n",
        "        hex_colors = [rgb_to_hex(rgb) for rgb in rgb_colors]\n",
        "\n",
        "        return {\n",
        "            'rgb_colors': rgb_colors,\n",
        "            'lab_colors': lab_colors,\n",
        "            'hex_colors': hex_colors,\n",
        "            'n_colors': len(rgb_colors)\n",
        "        }\n",
        "\n",
        "def hex_to_rgb(hex_color: str) -> Tuple[int, int, int]:\n",
        "    \"\"\"Convert HEX to RGB.\"\"\"\n",
        "    hex_color = hex_color.lstrip('#')\n",
        "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
        "\n",
        "def rgb_to_hex(rgb: Tuple[int, int, int]) -> str:\n",
        "    \"\"\"Convert RGB to HEX.\"\"\"\n",
        "    return '#{:02x}{:02x}{:02x}'.format(*rgb).upper()\n",
        "\n",
        "print(\"‚úì ColorFeatureExtractor loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Model/System Design\n",
        "\n",
        "**AI techinique used:** Used unsupervised Machine Learning(k-means clustering) for feature extraction and vector similarity search for the recommendation.\n",
        "\n",
        "##Pipeline:\n",
        "\n",
        "-Data injestion- Load the image data\n",
        "\n",
        "-Feature extraction- Extract the 5 dominant colour from each image\n",
        "\n",
        "-Indexing- Built a FAISS (Facebook AI Similarity Search) index for faster similarity search.\n",
        "\n",
        "-Input- User input for the colour of choice.\n",
        "\n",
        "##Justification for Design choice:\n",
        "\n",
        "-LAB colour space conversion: colour perception closest to how human percive them.\n",
        "\n",
        "-FAISS: to perform faster search."
      ],
      "metadata": {
        "id": "ZNiRVVC8OQXq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "indexing"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Indexing Module (FAISS)\n",
        "# ============================================================================\n",
        "\n",
        "import faiss\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ImageIndex:\n",
        "    \"\"\"Manages FAISS index for image similarity search.\"\"\"\n",
        "\n",
        "    def __init__(self, dimension: int = 15):\n",
        "        self.dimension = dimension\n",
        "        self.index = None\n",
        "        self.metadata = []\n",
        "        self.is_trained = False\n",
        "\n",
        "    def build_index(self, feature_vectors: np.ndarray, metadata: List[Dict],\n",
        "                   index_type: str = 'flat') -> None:\n",
        "        \"\"\"Build FAISS index from feature vectors.\"\"\"\n",
        "        if len(feature_vectors) != len(metadata):\n",
        "            raise ValueError(\"Number of feature vectors must match metadata length\")\n",
        "\n",
        "        logger.info(f\"Building FAISS index with {len(feature_vectors)} vectors\")\n",
        "\n",
        "        feature_vectors = feature_vectors.astype(np.float32)\n",
        "\n",
        "        if index_type == 'flat':\n",
        "            self.index = faiss.IndexFlatL2(self.dimension)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported index type: {index_type}\")\n",
        "\n",
        "        self.index.add(feature_vectors)\n",
        "        self.metadata = metadata\n",
        "        self.is_trained = True\n",
        "\n",
        "        logger.info(f\"Index built successfully with {self.index.ntotal} vectors\")\n",
        "\n",
        "    def search(self, query_vector: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Search for k nearest neighbors.\"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Index must be built before searching\")\n",
        "\n",
        "        if query_vector.ndim == 1:\n",
        "            query_vector = query_vector.reshape(1, -1)\n",
        "        query_vector = query_vector.astype(np.float32)\n",
        "\n",
        "        k = min(k, self.index.ntotal)\n",
        "        distances, indices = self.index.search(query_vector, k)\n",
        "\n",
        "        return distances[0], indices[0]\n",
        "\n",
        "    def get_statistics(self) -> Dict:\n",
        "        \"\"\"Get index statistics.\"\"\"\n",
        "        return {\n",
        "            'dimension': self.dimension,\n",
        "            'total_vectors': self.index.ntotal if self.index else 0,\n",
        "            'is_trained': self.is_trained,\n",
        "            'total_metadata': len(self.metadata)\n",
        "        }\n",
        "\n",
        "print(\"‚úì ImageIndex loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "similarity_search"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Similarity Search Module\n",
        "# ============================================================================\n",
        "\n",
        "from typing import Union\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ColorQueryEngine:\n",
        "    \"\"\"Query engine for color-based image similarity search.\"\"\"\n",
        "\n",
        "    def __init__(self, index: ImageIndex, extractor: ColorFeatureExtractor):\n",
        "        self.index = index\n",
        "        self.extractor = extractor\n",
        "\n",
        "    def parse_color_input(self, color_input: Union[str, Tuple, List]) -> Tuple[int, int, int]:\n",
        "        \"\"\"Parse color input to RGB.\"\"\"\n",
        "        if isinstance(color_input, str):\n",
        "            return hex_to_rgb(color_input)\n",
        "        elif isinstance(color_input, (tuple, list)):\n",
        "            if len(color_input) == 3:\n",
        "                return tuple(int(c) for c in color_input)\n",
        "            else:\n",
        "                raise ValueError(\"RGB input must have 3 values\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported color input type: {type(color_input)}\")\n",
        "\n",
        "    def create_query_vector_from_color(self, color_input: Union[str, Tuple, List]) -> np.ndarray:\n",
        "        \"\"\"Create query vector from a single color.\"\"\"\n",
        "        rgb = self.parse_color_input(color_input)\n",
        "        lab = self.extractor.rgb_to_lab(rgb)\n",
        "        feature_vector = np.array([lab] * self.extractor.n_colors).flatten()\n",
        "        return feature_vector.astype(np.float32)\n",
        "\n",
        "    def query_by_color(self, color_input: Union[str, Tuple, List], k: int = 10) -> List[Dict]:\n",
        "        \"\"\"Find images similar to a given color.\"\"\"\n",
        "        logger.info(f\"Querying by color: {color_input}\")\n",
        "\n",
        "        query_vector = self.create_query_vector_from_color(color_input)\n",
        "        search_k = min(k * 5, self.index.index.ntotal)\n",
        "        distances, indices = self.index.search(query_vector, search_k)\n",
        "\n",
        "        results = []\n",
        "        for dist, idx in zip(distances, indices):\n",
        "            metadata = self.index.metadata[idx].copy()\n",
        "            similarity = self.calculate_similarity_score(dist)\n",
        "\n",
        "            if similarity >= 0.70:\n",
        "                metadata['similarity_score'] = similarity\n",
        "                metadata['distance'] = float(dist)\n",
        "                results.append(metadata)\n",
        "\n",
        "                if len(results) >= k:\n",
        "                    break\n",
        "\n",
        "        return results\n",
        "\n",
        "    def query_by_image_path(self, image_path: str, k: int = 10,\n",
        "                           exclude_self: bool = True) -> List[Dict]:\n",
        "        \"\"\"Find images similar to an image at given path.\"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        query_vector = self.extractor.create_feature_vector(image)\n",
        "\n",
        "        search_k = k + 1 if exclude_self else k\n",
        "        distances, indices = self.index.search(query_vector, search_k)\n",
        "\n",
        "        results = []\n",
        "        for dist, idx in zip(distances, indices):\n",
        "            if exclude_self and dist < 0.01:\n",
        "                continue\n",
        "\n",
        "            metadata = self.index.metadata[idx].copy()\n",
        "            similarity = self.calculate_similarity_score(dist)\n",
        "\n",
        "            if similarity >= 0.70:\n",
        "                metadata['similarity_score'] = similarity\n",
        "                metadata['distance'] = float(dist)\n",
        "                results.append(metadata)\n",
        "\n",
        "            if len(results) >= k:\n",
        "                break\n",
        "\n",
        "        return results\n",
        "\n",
        "    def calculate_similarity_score(self, distance: float) -> float:\n",
        "        \"\"\"Convert distance to similarity score (0-1 range).\"\"\"\n",
        "        max_distance = 50000.0\n",
        "        similarity = max(0.0, 1.0 - (distance / max_distance))\n",
        "        return float(similarity)\n",
        "\n",
        "print(\"‚úì ColorQueryEngine loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "recommender"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Main Recommender Class\n",
        "# ============================================================================\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ColorRecommender:\n",
        "    \"\"\"Main API for color-based image recommendation system.\"\"\"\n",
        "\n",
        "    def __init__(self, n_colors: int = 5, quality: int = 10):\n",
        "        self.n_colors = n_colors\n",
        "        self.quality = quality\n",
        "\n",
        "        self.extractor = ColorFeatureExtractor(n_colors=n_colors, quality=quality)\n",
        "        self.index = ImageIndex(dimension=n_colors * 3)\n",
        "        self.query_engine = None\n",
        "        self.dataset = None\n",
        "\n",
        "    def build_from_directory(self, image_dir: str, recursive: bool = True,\n",
        "                            max_size: Optional[Tuple[int, int]] = (800, 800)) -> Dict:\n",
        "        \"\"\"Build recommendation system from image directory.\"\"\"\n",
        "        logger.info(\"=\" * 60)\n",
        "        logger.info(\"Building Color-Based Image Recommendation System\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Load images\n",
        "        logger.info(f\"\\n[1/3] Loading images from: {image_dir}\")\n",
        "        self.dataset = load_images_from_directory(image_dir, recursive, max_size)\n",
        "\n",
        "        if len(self.dataset.images) == 0:\n",
        "            raise ValueError(\"No images found in directory\")\n",
        "\n",
        "        logger.info(f\"Loaded {len(self.dataset.images)} images\")\n",
        "\n",
        "        # Extract features\n",
        "        logger.info(f\"\\n[2/3] Extracting color features...\")\n",
        "        feature_vectors = []\n",
        "        metadata = []\n",
        "\n",
        "        for i, img_data in enumerate(self.dataset.images):\n",
        "            if (i + 1) % 10 == 0:\n",
        "                logger.info(f\"Processing image {i + 1}/{len(self.dataset.images)}\")\n",
        "\n",
        "            try:\n",
        "                feature_vec = self.extractor.create_feature_vector(img_data['image'])\n",
        "                feature_vectors.append(feature_vec)\n",
        "\n",
        "                meta = {\n",
        "                    'path': img_data['path'],\n",
        "                    'filename': img_data['filename'],\n",
        "                    'size': img_data['size']\n",
        "                }\n",
        "                metadata.append(meta)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed to process {img_data['filename']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        feature_vectors = np.array(feature_vectors)\n",
        "        logger.info(f\"Extracted features from {len(feature_vectors)} images\")\n",
        "\n",
        "        # Build index\n",
        "        logger.info(f\"\\n[3/3] Building FAISS index...\")\n",
        "        self.index.build_index(feature_vectors, metadata)\n",
        "\n",
        "        # Initialize query engine\n",
        "        self.query_engine = ColorQueryEngine(self.index, self.extractor)\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        stats = {\n",
        "            'total_images': len(self.dataset.images),\n",
        "            'indexed_images': len(feature_vectors),\n",
        "            'build_time_seconds': elapsed_time,\n",
        "            'n_colors': self.n_colors,\n",
        "            'feature_dimension': self.index.dimension\n",
        "        }\n",
        "\n",
        "        logger.info(\"\\n\" + \"=\" * 60)\n",
        "        logger.info(\"Build Complete!\")\n",
        "        logger.info(f\"Total images: {stats['total_images']}\")\n",
        "        logger.info(f\"Indexed images: {stats['indexed_images']}\")\n",
        "        logger.info(f\"Build time: {stats['build_time_seconds']:.2f} seconds\")\n",
        "        logger.info(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def recommend_by_color(self, color: Union[str, Tuple, List], k: int = 10) -> List[Dict]:\n",
        "        \"\"\"Get image recommendations based on color similarity.\"\"\"\n",
        "        if self.query_engine is None:\n",
        "            raise ValueError(\"Index not built. Call build_from_directory() first.\")\n",
        "        return self.query_engine.query_by_color(color, k)\n",
        "\n",
        "    def recommend_by_image(self, image_path: str, k: int = 10,\n",
        "                          exclude_self: bool = True) -> List[Dict]:\n",
        "        \"\"\"Get image recommendations based on image similarity.\"\"\"\n",
        "        if self.query_engine is None:\n",
        "            raise ValueError(\"Index not built. Call build_from_directory() first.\")\n",
        "        return self.query_engine.query_by_image_path(image_path, k, exclude_self)\n",
        "\n",
        "    def get_statistics(self) -> Dict:\n",
        "        \"\"\"Get system statistics.\"\"\"\n",
        "        stats = {\n",
        "            'n_colors': self.n_colors,\n",
        "            'quality': self.quality\n",
        "        }\n",
        "\n",
        "        if self.index:\n",
        "            stats.update(self.index.get_statistics())\n",
        "\n",
        "        if self.dataset:\n",
        "            stats.update(self.dataset.get_statistics())\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def get_image_colors(self, image_path: str) -> Dict:\n",
        "        \"\"\"Get dominant colors for a specific image.\"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        return self.extractor.extract_color_palette(image)\n",
        "\n",
        "print(\"‚úì ColorRecommender loaded!\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ALL MODULES LOADED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "build_section"
      },
      "source": [
        "## 4Ô∏è‚É£ Core Implementation\n",
        "\n",
        "No model training in the traditional sense. It builds a searchable index from the dominat colours extracted from the images.\n",
        "\n",
        "\n",
        "##Recommendation Pipeline:\n",
        "The above cell for the [class ColorRecommende] brings all the modules together into a singular worflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "build_index"
      },
      "outputs": [],
      "source": [
        "# Initialize and build the recommendation system\n",
        "print(\"üî® Building index from your images...\")\n",
        "print(\"This will take ~1-2 seconds per image.\\n\")\n",
        "\n",
        "recommender = ColorRecommender(n_colors=5, quality=10)\n",
        "\n",
        "stats = recommender.build_from_directory(\n",
        "    image_dir=IMAGE_DIR,\n",
        "    recursive=True,\n",
        "    max_size=(800, 800)\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ INDEX READY!\")\n",
        "print(f\"   Total images indexed: {stats['indexed_images']}\")\n",
        "print(f\"   Build time: {stats['build_time_seconds']:.2f} seconds\")\n",
        "print(f\"   Feature dimension: {stats['feature_dimension']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive_section"
      },
      "source": [
        "## 5Ô∏è‚É£ Evaluation & Analysis\n",
        "\n",
        "##Output\n",
        "\n",
        "The outputs after running the model are mostly correct. Due to not have a bigger dataset(more images) the clustering for certain images are conflicting between 2 colours as you will be able to see below.\n",
        "\n",
        "##Performance and Limitation.\n",
        "\n",
        "Due to lack of a bigger dataset some colours may show no images as a result. Also if the dataset lacks variety, colour separation of images are harder to identify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_function"
      },
      "outputs": [],
      "source": [
        "# Results display function\n",
        "def display_results(results, query_color, query_time_ms):\n",
        "    \"\"\"Display search results in matplotlib grid.\"\"\"\n",
        "    n_results = len(results)\n",
        "    cols = 4\n",
        "    rows = (n_results + cols - 1) // cols\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))\n",
        "\n",
        "    if rows == 1 and cols == 1:\n",
        "        axes = np.array([[axes]])\n",
        "    elif rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    elif cols == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, result in enumerate(results):\n",
        "        try:\n",
        "            img = Image.open(result['path'])\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "            similarity = result['similarity_score'] * 100\n",
        "            filename = result['filename'][:30] + '...' if len(result['filename']) > 30 else result['filename']\n",
        "\n",
        "            axes[idx].set_title(\n",
        "                f\"{filename}\\n‚úì {similarity:.1f}% match\",\n",
        "                fontsize=9,\n",
        "                pad=5,\n",
        "                fontweight='bold' if similarity > 80 else 'normal'\n",
        "            )\n",
        "        except Exception as e:\n",
        "            axes[idx].text(0.5, 0.5, f'Error loading\\n{result[\"filename\"]}',\n",
        "                          ha='center', va='center', fontsize=8)\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "    for idx in range(n_results, len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    fig.suptitle(\n",
        "        f\"üé® Query Color: {query_color}  |  üìä {n_results} Results  |  ‚ö° {query_time_ms:.2f}ms\",\n",
        "        fontsize=14,\n",
        "        fontweight='bold',\n",
        "        y=0.98\n",
        "    )\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úì Display function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "widgets"
      },
      "outputs": [],
      "source": [
        "# Interactive color search widget\n",
        "color_picker = widgets.ColorPicker(\n",
        "    concise=False,\n",
        "    description='üé® Pick Color:',\n",
        "    value='#FF5733',\n",
        "    disabled=False,\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "k_slider = widgets.IntSlider(\n",
        "    value=12,\n",
        "    min=1,\n",
        "    max=50,\n",
        "    step=1,\n",
        "    description='üî¢ Results:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "search_btn = widgets.Button(\n",
        "    description='üîç Search Images',\n",
        "    button_style='success',\n",
        "    tooltip='Click to search for similar images',\n",
        "    icon='search',\n",
        "    layout=widgets.Layout(width='200px', height='40px')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_search_clicked(btn):\n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        color = color_picker.value\n",
        "        k = k_slider.value\n",
        "\n",
        "        print(f\"üîç Searching for {k} images with color: {color}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = recommender.recommend_by_color(color, k=k)\n",
        "        query_time = (time.time() - start_time) * 1000\n",
        "\n",
        "        if not results:\n",
        "            print(\"‚ùå No results found!\")\n",
        "            return\n",
        "\n",
        "        print(f\"‚úì Found {len(results)} results in {query_time:.2f}ms\\n\")\n",
        "        display_results(results, color, query_time)\n",
        "\n",
        "search_btn.on_click(on_search_clicked)\n",
        "\n",
        "display(HTML(\"<h2>üé® Color-Based Image Search</h2>\"))\n",
        "display(widgets.VBox([\n",
        "    widgets.HBox([color_picker, k_slider]),\n",
        "    search_btn,\n",
        "    output_area\n",
        "], layout=widgets.Layout(padding='10px')))\n",
        "\n",
        "print(\"\\nüëÜ Pick a color and click 'Search Images'!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_section"
      },
      "source": [
        "## 6Ô∏è‚É£ Ethical Consideration & Responsible AI\n",
        "\n",
        "##Bias & Fairness:\n",
        "\n",
        "Entirely dependent on the availabe user input data, if the dataset is not lager enough or diverse enough the result will reflect in the output of the model.\n",
        "\n",
        "##Dataset Limitations:\n",
        "\n",
        "It is designed for local directories for now.\n",
        "\n",
        "##Responsible Use:\n",
        "\n",
        "Input validation check for file types and file formats.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7Ô∏è‚É£ Conclusion & Future Scope.\n",
        "\n",
        "The system sucessufully processes local image catelogs to build high-speed search indexes, allowing us to find images with 70% colour similariity.\n",
        "\n",
        "##Improvements\n",
        "\n",
        "- build for more complex filtering.\n",
        "- upgrading for larger datasets.\n",
        "- use for different situations (Clothes recommendation in the fashion industry. Furniture recommendation for interior designer.)\n",
        "\n",
        "The core system remains the same, but the use case changes based on the user."
      ],
      "metadata": {
        "id": "riG5oirHXTnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_colors"
      },
      "outputs": [],
      "source": [
        "# Analyze colors in a specific image\n",
        "# Uncomment and modify path:\n",
        "\n",
        "# image_path = 'images/your_image.jpg'  # Change this!\n",
        "# colors = recommender.get_image_colors(image_path)\n",
        "#\n",
        "# print(\"Dominant Colors:\")\n",
        "# for i, (rgb, hex_code) in enumerate(zip(colors['rgb_colors'], colors['hex_colors'])):\n",
        "#     print(f\"  Color {i+1}: {hex_code} - RGB{rgb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reverse_search"
      },
      "outputs": [],
      "source": [
        "# Reverse image search (find similar images)\n",
        "# Uncomment and modify path:\n",
        "\n",
        "# query_image = 'images/your_image.jpg'  # Change this!\n",
        "# similar = recommender.recommend_by_image(query_image, k=10, exclude_self=True)\n",
        "#\n",
        "# print(f\"Images similar to {query_image}:\")\n",
        "# for img in similar:\n",
        "#     print(f\"  {img['filename']}: {img['similarity_score']*100:.1f}% match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stats"
      },
      "outputs": [],
      "source": [
        "# # View system statistics\n",
        "# stats = recommender.get_statistics()\n",
        "\n",
        "# print(\"=\"*60)\n",
        "# print(\"üìä SYSTEM STATISTICS\")\n",
        "# print(\"=\"*60)\n",
        "# for key, value in stats.items():\n",
        "#     print(f\"  {key}: {value}\")\n",
        "# print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips"
      },
      "source": [
        "## üí° Tips & Usage\n",
        "\n",
        "### Color Search:\n",
        "```python\n",
        "# By HEX code\n",
        "results = recommender.recommend_by_color('#FF5733', k=10)\n",
        "\n",
        "# By RGB tuple\n",
        "results = recommender.recommend_by_color((255, 87, 51), k=10)\n",
        "```\n",
        "\n",
        "### Popular Colors to Try:\n",
        "- **Vibrant Red**: `#FF5733`\n",
        "- **Ocean Blue**: `#3498DB`\n",
        "- **Forest Green**: `#2ECC71`\n",
        "- **Sunset Orange**: `#FF8C42`\n",
        "- **Royal Purple**: `#9B59B6`\n",
        "- **Hot Pink**: `#E91E63`\n",
        "\n",
        "### Notes:\n",
        "- Results are filtered at 70% similarity threshold\n",
        "- FAISS uses exact L2 distance (no approximation)\n",
        "- Query time typically 5-50ms depending on index size\n",
        "- All code is embedded in this notebook - no external files needed!\n",
        "\n",
        "---\n",
        "\n",
        "**Enjoy your color-based image search! üé®**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}